{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Training_Model notebook\n",
    "\n",
    "Goals of this notebook:\n",
    "* Train a Model to classify suspicious firms as such, given their data\n",
    "\n",
    "###### The Auditor Office of India, officially known as the Comptroller and Auditor General of India (CAG), is a Central Government Agency established by the Indian Constitution with the express purpose of ensuring public funds are being used properly (making sure the gov't isn't being scammed). It does this by auditing Central and State Government accounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "The dataset is the 'Audit Data' dataset from the UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = pd.read_csv('../audit_data/audit_risk.csv') # 'ad' for 'audit data'\n",
    "td = pd.read_csv('../audit_data/trial.csv') # 'td' for 'trial data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sector_score', 'LOCATION_ID', 'PARA_A', 'Score_A', 'Risk_A', 'PARA_B',\n",
      "       'Score_B', 'Risk_B', 'TOTAL', 'numbers', 'Score_B.1', 'Risk_C',\n",
      "       'Money_Value', 'Score_MV', 'Risk_D', 'District_Loss', 'PROB', 'RiSk_E',\n",
      "       'History', 'Prob', 'Risk_F', 'Score', 'Inherent_Risk', 'CONTROL_RISK',\n",
      "       'Detection_Risk', 'Audit_Risk', 'Risk'],\n",
      "      dtype='object')\n",
      "Index(['Sector_score', 'LOCATION_ID', 'PARA_A', 'SCORE_A', 'PARA_B', 'SCORE_B',\n",
      "       'TOTAL', 'numbers', 'Marks', 'Money_Value', 'MONEY_Marks', 'District',\n",
      "       'Loss', 'LOSS_SCORE', 'History', 'History_score', 'Score', 'Risk'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>...</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Risk_F</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>Detection_Risk</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2.37</td>\n",
       "      <td>28</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.050</td>\n",
       "      <td>1.54</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.966</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1.85</td>\n",
       "      <td>19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.200</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>21.61</td>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.546</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>3.41</td>\n",
       "      <td>13</td>\n",
       "      <td>5.61</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.366</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.312</td>\n",
       "      <td>7.17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.884</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>59.85</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.540</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2.37</td>\n",
       "      <td>2</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.308</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.186</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.694</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.2164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3.41</td>\n",
       "      <td>34</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.550</td>\n",
       "      <td>45.51</td>\n",
       "      <td>0.6</td>\n",
       "      <td>27.306</td>\n",
       "      <td>49.76</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>35.736</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.1472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3.89</td>\n",
       "      <td>22</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.770</td>\n",
       "      <td>6.56</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.624</td>\n",
       "      <td>9.51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>99.946</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>19.9892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3.41</td>\n",
       "      <td>16</td>\n",
       "      <td>12.68</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.608</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.600</td>\n",
       "      <td>53.68</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>41.936</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.3872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.89</td>\n",
       "      <td>20</td>\n",
       "      <td>9.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.406</td>\n",
       "      <td>19.82</td>\n",
       "      <td>0.6</td>\n",
       "      <td>11.892</td>\n",
       "      <td>28.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>22.566</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sector_score LOCATION_ID  PARA_A  Score_A  Risk_A  PARA_B  Score_B  \\\n",
       "303          2.37          28    1.29      0.4   0.516    0.25      0.2   \n",
       "477          1.85          19    0.00      0.2   0.000    0.00      0.2   \n",
       "512         21.61           8    0.34      0.2   0.068    0.36      0.2   \n",
       "162          3.41          13    5.61      0.6   3.366    1.56      0.2   \n",
       "546         59.85          11    0.00      0.2   0.000    0.00      0.2   \n",
       "324          2.37           2    2.18      0.6   1.308    0.93      0.2   \n",
       "114          3.41          34    4.25      0.6   2.550   45.51      0.6   \n",
       "49           3.89          22    2.95      0.6   1.770    6.56      0.4   \n",
       "140          3.41          16   12.68      0.6   7.608   41.00      0.6   \n",
       "36           3.89          20    9.01      0.6   5.406   19.82      0.6   \n",
       "\n",
       "     Risk_B  TOTAL  numbers  ...  RiSk_E  History  Prob  Risk_F  Score  \\\n",
       "303   0.050   1.54      5.0  ...     0.4        0   0.2     0.0    2.2   \n",
       "477   0.000   0.00      5.0  ...     1.2        0   0.2     0.0    2.4   \n",
       "512   0.072   0.70      5.0  ...     0.4        0   0.2     0.0    2.0   \n",
       "162   0.312   7.17      5.0  ...     0.4        0   0.2     0.0    2.4   \n",
       "546   0.000   0.00      5.0  ...     0.4        0   0.2     0.0    2.0   \n",
       "324   0.186   3.11      5.0  ...     1.2        0   0.2     0.0    2.8   \n",
       "114  27.306  49.76      5.5  ...     0.4        0   0.2     0.0    4.2   \n",
       "49    2.624   9.51      5.0  ...     0.4        0   0.2     0.0    3.4   \n",
       "140  24.600  53.68      5.5  ...     0.4        0   0.2     0.0    4.4   \n",
       "36   11.892  28.83      5.0  ...     0.4        0   0.2     0.0    3.8   \n",
       "\n",
       "     Inherent_Risk  CONTROL_RISK  Detection_Risk  Audit_Risk  Risk  \n",
       "303          1.966           0.4             0.5      0.3932     0  \n",
       "477          2.200           1.2             0.5      1.3200     1  \n",
       "512          1.546           0.4             0.5      0.3092     0  \n",
       "162          5.884           0.4             0.5      1.1768     1  \n",
       "546          1.540           0.4             0.5      0.3080     0  \n",
       "324          3.694           1.2             0.5      2.2164     1  \n",
       "114         35.736           0.4             0.5      7.1472     1  \n",
       "49          99.946           0.4             0.5     19.9892     1  \n",
       "140         41.936           0.4             0.5      8.3872     1  \n",
       "36          22.566           0.4             0.5      4.5132     1  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ad.columns) # to see the different columns that ad and td have\n",
    "print(td.columns)\n",
    "\n",
    "ad.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PCA to determine the relative importance of each feature\n",
    "\n",
    "Just for funsies, not sure it will work. Will do for both ad and td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating 'ad' for NaN values and readying it for pca:\n",
      "\n",
      "Shape of the original ad is (776, 27)\n",
      "Shape after removing the 3 rows with Loharu Nuh and Safidon is (773, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector_score</th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>Score_A</th>\n",
       "      <th>Risk_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>Score_B</th>\n",
       "      <th>Risk_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Score_B.1</th>\n",
       "      <th>Risk_C</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>Score_MV</th>\n",
       "      <th>Risk_D</th>\n",
       "      <th>District_Loss</th>\n",
       "      <th>PROB</th>\n",
       "      <th>RiSk_E</th>\n",
       "      <th>History</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Risk_F</th>\n",
       "      <th>Score</th>\n",
       "      <th>Inherent_Risk</th>\n",
       "      <th>CONTROL_RISK</th>\n",
       "      <th>Detection_Risk</th>\n",
       "      <th>Audit_Risk</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>55.57</td>\n",
       "      <td>4</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sector_score LOCATION_ID  PARA_A  Score_A  Risk_A  PARA_B  Score_B  \\\n",
       "642         55.57           4    0.23      0.2   0.046     0.0      0.2   \n",
       "\n",
       "     Risk_B  TOTAL  numbers  Score_B.1  Risk_C  Money_Value  Score_MV  Risk_D  \\\n",
       "642     0.0   0.23      5.0        0.2     1.0          NaN       0.2     0.0   \n",
       "\n",
       "     District_Loss  PROB  RiSk_E  History  Prob  Risk_F  Score  Inherent_Risk  \\\n",
       "642              2   0.2     0.4        0   0.2     0.0    2.0          1.446   \n",
       "\n",
       "     CONTROL_RISK  Detection_Risk  Audit_Risk  Risk  \n",
       "642           0.4             0.5      0.2892     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping na is (772, 27)\n",
      "Pca section - using pca to find the relative importance(explained variance) of each column:\n",
      "\n",
      "Audit Data (ad) columns and explained variance:\n",
      "\n",
      "Index(['Sector_score\\n', 'LOCATION_ID\\n', 'PARA_A\\n', 'Score_A\\n', 'Risk_A\\n',\n",
      "       'PARA_B\\n', 'Score_B\\n', 'Risk_B\\n', 'TOTAL\\n', 'numbers\\n',\n",
      "       'Score_B.1\\n', 'Risk_C\\n', 'Money_Value\\n', 'Score_MV\\n', 'Risk_D\\n',\n",
      "       'District_Loss\\n', 'PROB\\n', 'RiSk_E\\n', 'History\\n', 'Prob\\n',\n",
      "       'Risk_F\\n', 'Score\\n', 'Inherent_Risk\\n', 'CONTROL_RISK\\n',\n",
      "       'Detection_Risk\\n', 'Audit_Risk\\n', 'Risk\\n'],\n",
      "      dtype='object')\n",
      "[0.6288 0.3171 0.0336 0.0123 0.0052 0.0027 0.0001 0.0001 0.     0.\n",
      " 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.     0.     0.    ]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display #display module for jupyter notebook, allowing me to manually force Jupyter to display in the nice UI form\n",
    "\n",
    "#INVESTGATING 'ad' FOR NaN values / READYING IT FOR PCA\n",
    "print('Investigating \\'ad\\' for NaN values and readying it for pca:\\n')\n",
    "\n",
    "ad.loc[ad.LOCATION_ID.isin(['LOHARU', 'NUH', 'SAFIDON'])] #find the row index numbers where these strings are in LOCATION_ID\n",
    "\n",
    "#print(ad.head(10))\n",
    "ad_stringless = ad.copy().drop([351,355,367], axis=0)\n",
    "print(f'Shape of the original ad is {ad.shape}')\n",
    "print(f'Shape after removing the 3 rows with Loharu Nuh and Safidon is {ad_stringless.shape}')\n",
    "pd.set_option('display.max_columns', None)\n",
    "#print(ad_stringless.isna().any(axis=0)) # checks if there's an NA in any column, and if so, labels that column as \"True\"\n",
    "display(ad_stringless[ad_stringless.isna().any(axis=1)]) # returns the rows with at least 1 box that is NA, in the nice UI form\n",
    "\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "ad_stringless = ad_stringless.dropna()\n",
    "print(f'Shape after dropping na is {ad_stringless.shape}')\n",
    "\n",
    "\n",
    "# PCA SECTION - USING PCA TO FIND HOW IMPORTANT EACH COLUMN IS\n",
    "print('Pca section - using pca to find the relative importance(explained variance) of each column:\\n')\n",
    "\n",
    "# PCA and Pandas are already imported\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(ad_stringless)\n",
    "ad_explained_variance_ratio = pca.explained_variance_ratio_ # must be ratio, otherwise it's just absolute values that don't really mean much to us\n",
    "\n",
    "print('Audit Data (ad) columns and explained variance:\\n')\n",
    "print(ad.columns + '\\n')\n",
    "np.set_printoptions(precision=4, suppress=True) \n",
    "print(ad_explained_variance_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td version of the section above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discoveries made about ad and td\n",
    "\n",
    "1. In both 'ad' and 'td', there are 3 rows where the LOCATION_ID is string, so it is not a float, and hence not compatible with pca. Hence, they were removed.\n",
    "2. In 'ad', for some reason, in row 642, 'Money_Value' is NaN. So, I removed the row.\n",
    "3. For 'ad', it appears that the location and first couple of 'para's hold the majority of the file's data variety (explained variance)\n",
    "    This means that the location and first 2 'para's vary the most throughout the data. The location makes sense, but this could also imply that  columns 9-27 are relatively similar across firms. We can't entirely be sure without more information or investigation.\n",
    "\n",
    "Note: I am removing pca-incompatible rows because I believe that in the face of 770+ rows, those individual rows probably don't matter too much. In other words, removing them is worth it for the ability to use PCA to learn more about the columns in the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self: in the next section, do logistic regression on ad and td without pca.\n",
    "\n",
    "then, in the section after that, do logistic regression on ad and td post-pca. the pca work should have been completed above, so just grab ad_stringless and td_stringless to throw into train_test_split. Have to isolate the 'Risk' row though(pull out of these dataframes and separate into its own series), since it is the target."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
